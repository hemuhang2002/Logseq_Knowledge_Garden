background-color:: purple
|文章名称|时间|创新点和特点|代码状态|
|--|--|--|--|
|ST - GCN|2018|设计了基于spatial的三重邻接矩阵的方法，然后先gcn再tcn，spatial已经是基础的方法| 已读|
|PB - GCN|2019|设计了基于part的卷积方法，最后再聚合，**时间卷积通过多尺度时间卷积，比较常用了**| 已读|
|2s - AGCN|2019| **双流**框架，对邻接矩阵进行了改进，使用non local操作得到了一个可学习的edge邻接矩阵|已读|
|Motif -- GCN | 2019 | 预先设置的motif | 未读，论文再看|
|SGN|2019|融合了节点和时间帧的语义性，具有轻量化的特点|未读|
|Ce-CNN | 2019 | 改进了non local机制，提出的新的课学习邻接矩阵可以根据全局信息进行编码，**操作是把时间和节点分别当做通道维度进行卷积**，启发，可以对时间维度进行卷积，再去获取邻接矩阵，因为手臂的颤动可能在整个时间段，也可能在不同的时间段，全局编码更有利于提取这一特征。**最后一步1*1卷积的操作是否没有完全利用全局信息？可以考虑改进，这篇论文纳入毕设框架**|未读|
|MS - G3D | 2020 | **解耦多尺度邻接矩阵** | 未读 |
|CTR - GCN | 2021| 设计了对**每个通道进行细化的邻接矩阵**，通过矩阵操作得到了通道的邻接矩阵，在用多尺度时间卷积 | 已读|
|ST-TR|2020| 将transformer机制引入，对时间帧内节点和每个节点跨时间的实现了注意力机制。transformer和non local感觉差不多，但是本文在**每个节点跨时间**的操作值得学习，同时本文有开源代码|未读|
|PartResGCN |2020| 首先在后续卷积前把三个模态的特征提取并且融合（毕设没必要，应该没啥计算量），然后resnet操作，**最后是基于part的attention操作，这个点值得学习，因为毕业设计中可能需要在手和肩膀间加上注意力操作，或许可以直接使用分区**|未读|
|Decoupling GCN|2020|**Grop - GCN机制的引入**，有开源代码，对于GCN的正则化和drop机制有改进，不过可能对毕业设计没多大帮助|未读|
|Shift GCN | 2020 | 使用了CNN中的shift操作，轻量化模型并且能够提升准确度，又时间和空间的shift，**可以作为毕业设计的改进，但是目前可能用不上这个操作**| 未读|
|MV-IGNet|2020|很庞大的工作，具体来说有三点值得学习①**使用了deepwise和pointwise来计算GCN，而不是用相同的图拓扑，同时pointwise操作可以减少计算量。**②GAC操作，全局注意力来对SPG-Conv的权重进行注意力③**使用1-A0的操作来实现multi-view**，很新奇的想法。代码开源|未读|
|Dynamic - 3D|2020| **①运动输入  位置、速度、加速度。**②分区域卷积，最后进行Multiscale 操作，对于不同区域之间的状态进行进行交叉指导，进行融合。代码开源|未读|
|CA-GCN|2020|**①计算语义模块，把这个新的语义特征当作每个一个点的附加特征值（concact在原始特征后面，也可以加在原始特征上），再进行正常的GCN-TCN。**②在如何计算语义特征上，作者提出了简化版和进阶版模型，进阶版模型就是先把每个点特征做一次MLP得到所谓的高级特征，再对这些高级特征进行相关性计算（**相关性计算和简化版一样，核心是计算点积，可以直接点积也可以使用可训练权重进行计算**）得到语义。之后的处理就一样了。**③作者还提出了计算语义的时候，边和点同时纳入语义计算的范围。** 语义添加可以考虑作为毕业设计中的处理，然后这个边和点同时纳入也可以考虑，因为毕业设计里面不涉及很多的点边，纳入可能不需要太多额外的计算。最后毕业设计如果使用这篇文献的话，需要考虑做改进，或者融合之前的文献中的点进行改进，感觉语义可以用，但是也可以直接用之前的注意力模块，这里的语义计算可以考虑怎样改进。|未读|
|efficient GCN|2021|对PartResGCN的改进 ①建模输入：节点（位置和相对位置）；速度（速度和加速度）；骨架（长度和角度）②**中间使用了可分离的卷积操作（需要详细看代码）**③注意力机制是对节点和时间帧统一建模，感觉和CeGCN前一步很相似，**最后一步处理时间和节点的池化操作有不一样。**（代码很重要需要学习）--**同时，如果提取时间和节点特征用CeGCN的操作，然后处理时间和节点降维之后的操作使用本文方法，可能算是一种创新。**|**未读**|
|MMDGCN|2021|三个创新①每一个GCN都是添加了RES操作，并且重复添加，保证最后的特征也包含前面的特征。②在每一个res分支上，**都有STAM时空注意力操作，该操作的代码实现很重要。**③多尺度时间卷积，就是几个时间卷积然后concact，**最后通过一个W权重层来调整每一个时间卷积的重要性。**|未读|
|PSUMnet|2022|四个创新①**首先分组，每个组有交叉的节点，因为很多动作并不需要完整的骨架就可以判断，如踢、握手等动作②对每个分组进行数据处理为骨架、节点、节点速度和骨架速度四个模态**③为了计算注意力机制，使用了减法，不知道为啥……④总的来说很轻量，可以部署在嵌入式设备上。代码开源|未读|

- 骨架识别非GCN工作
  | 名称 |时间|代码状态|
  |--|--|--|
  |JOLO GCN|2020|光流改进，可以融入GCN中，开源|
  |PCRP|2020|无监督骨架识别，开源代码|
  |Pose3DCNN|2022|①无需额外的计算量，可以处理任意人数②效果比GCN好③将骨架信息转化为3D热图，具有很好的与其他模态相融合的能力。|
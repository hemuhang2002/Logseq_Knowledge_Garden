- 参考链接：[提示学习(Prompt Learning)——低资源场景的福音 ](https://zhuanlan.zhihu.com/p/406291495)
- 定义：概括来讲，提示学习是这样一类学习方法：在**不显著改变**预训练语言模型结构和参数的情况下，通过向输入增加“提示信息”、将下游任务改为文本生成任务
- 理解：预训练语言模型中存在很多知识和模式，有的是现成的、可以直接使用，有的则需要一定的方法来**“激发”**出来
- 零样本学习：
	- 总的来说，预训练语言模型学到了一些简单的知识和字符串模式。对于某些（无法确切定义范围的）知识，我们可以使用简单的模板构造填空题，引导BERT回答。因此我们说包括BERT在内的很多预训练语言模型具有“零样本学习”能力。
	- 典型的提示学习方法，则是在不对预训练语言模型进行微调的情况下，只依靠提示信息来引导模型完成下游任务。
- 少样本学习：使用(chnsenticorp训练集中随机抽取)200个样本对BERT进行微调，模型就可以在（chnsenticorp训练集中随机抽取的另外）100个样本中达到77%的正确率。
- LAMA:
	- 可以看到，需要预测的Object在BERT的预训练语料中出现的次数越高，
- AUTOPROMPT
	- 他们的具体做法是，不对预训练语言模型做任何改动（结构或参数），使用基于梯度搜索得到的优质提示模板，就可以让预训练语言模型具有良好的文本分类能力。
- 参考链接：[【NLP】Prompt Learning 超强入门教程 (zhihu.com)](https://www.zhihu.com/tardis/zm/art/442486331?source_id=1005)
	- Prompt 是一种**为了更好的使用预训练语言模型的知识**，采用在输入段**添加额外的文本**的技术。
		- - 目的：更好挖掘预训练语言模型的能力
		- - 手段：在输入端添加文本，即重新定义任务（task reformulation）
	- 为什么需要Prompt？
		- 如何构造合适的Prompt 模版？对于同一个任务，不同的人可能构造不同的Template。
- 未来方向：Prompt Learning 和多模态
-